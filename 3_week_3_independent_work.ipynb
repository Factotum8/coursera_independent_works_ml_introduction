{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Логистическая регрессия](https://www.coursera.org/learn/vvedenie-mashinnoe-obuchenie/programming/MptFX/loghistichieskaia-rieghriessiia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузите данные из файла data-logistic.csv. Это двумерная выборка, целевая переменная на которой принимает значения -1 или 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>first_feature</th>\n",
       "      <th>second_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.663827</td>\n",
       "      <td>-0.138526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.994596</td>\n",
       "      <td>2.468025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1.247395</td>\n",
       "      <td>0.749425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.309374</td>\n",
       "      <td>1.899836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.849143</td>\n",
       "      <td>2.407750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  first_feature  second_feature\n",
       "0      -1      -0.663827       -0.138526\n",
       "1       1       1.994596        2.468025\n",
       "2      -1      -1.247395        0.749425\n",
       "3       1       2.309374        1.899836\n",
       "4       1       0.849143        2.407750"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "data = pd.read_csv('./data/data-logistic.csv', sep=\",\", names=['target', 'first_feature', 'second_feature']) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Убедитесь, что [выше](https://www.coursera.org/learn/vvedenie-mashinnoe-obuchenie/programming/MptFX/loghistichieskaia-rieghriessiia) выписаны правильные формулы для градиентного спуска. Обратите внимание, что мы используем полноценный градиентный спуск, а не его стохастический вариант!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['first_feature', 'second_feature']]\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализуйте градиентный спуск для обычной и L2-регуляризованной (с коэффициентом регуляризации 10) логистической регрессии. Используйте длину шага k=0.1. В качестве начального приближения используйте вектор (0, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import exp\n",
    "weights = [0.0, 0.0]\n",
    "k = 0.1\n",
    "l = len(data)\n",
    "C = 10  # Коэффициент регуляризации\n",
    "e = lambda x, y: np.sqrt((x[0] - y[0])**2 + (x[1] - y[1])**2)\n",
    "step_count = 10_000\n",
    "accuracy = 10**-5\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish iteraion: 237 e: 9.83606356347748e-06\n"
     ]
    }
   ],
   "source": [
    " def logistic_regression(X, y, weights_, k, C, accur_, step_count_):\n",
    "    n = 0\n",
    "    w1 = weights_[0]\n",
    "    w2 = weights_[1]\n",
    "    l = len(data)\n",
    "    # (n < step_count_) and ((weight_delta_1 > accur_) or (weight_delta_2 > accur_)):\n",
    "    while True:\n",
    "        \n",
    "        previous_w1 = w1\n",
    "        previous_w2 = w2\n",
    "        \n",
    "        w1 = \\\n",
    "        w1 + k / l * sum(x_i1 * y_i * (1 - 1 / (1 + exp(-y_i * (w1 * x_i1 + w2 * x_i2)))) \n",
    "                         for x_i1, x_i2, y_i in zip(X['first_feature'], X['second_feature'], y))\n",
    "        \n",
    "        w2 = \\\n",
    "        w2 + k / l* sum(y_i * x_i2 * (1 - 1 / (1 + exp(-y_i * (w1 * x_i1 + w2 * x_i2)))) \n",
    "                        for x_i1, x_i2, y_i in zip(X['first_feature'], X['second_feature'], y))\n",
    "\n",
    "        e_ = e([w1, w2], [previous_w1, previous_w2])\n",
    "\n",
    "        n += 1\n",
    "\n",
    "        if (n > step_count_) or ( e_ < accur_):\n",
    "            print(f\"finish iteraion: {n + 1} e: {e_}\")\n",
    "            break\n",
    "    return w1, w2\n",
    "\n",
    "w1, w2 = logistic_regression(X, y, weights, k, C, accuracy, step_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish iteraion: 7 e: 5.833626427089232e-06\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression_l2(X, y, weights_, k, C, accur_, step_count_):\n",
    "    n = 0\n",
    "    w1 = weights_[0]\n",
    "    w2 = weights_[1]\n",
    "    l = len(data)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        previous_w1 = w1\n",
    "        previous_w2 = w2\n",
    "        \n",
    "        w1 = \\\n",
    "        w1 + k / l * sum(x_i1 * y_i * (1 - 1 / (1 + exp(-y_i * (w1 * x_i1 + w2 * x_i2)))) \n",
    "                         for x_i1, x_i2, y_i in zip(X['first_feature'], X['second_feature'], y)) - k * C * w1\n",
    "        \n",
    "        w2 = \\\n",
    "        w2 + k / l* sum(y_i * x_i2 * (1 - 1 / (1 + exp(-y_i * (w1 * x_i1 + w2 * x_i2)))) \n",
    "                        for x_i1, x_i2, y_i in zip(X['first_feature'], X['second_feature'], y)) - k * C * w2\n",
    "\n",
    "        e_ = e([w1, w2], [previous_w1, previous_w2])\n",
    "        n += 1\n",
    "        \n",
    "        if (n > step_count_) or (e_ < accur_):\n",
    "            print(f\"finish iteraion: {n + 1} e: {e_}\")\n",
    "            break\n",
    "    return w1, w2\n",
    "\n",
    "w1_l2, w2_l2 = logistic_regression_l2(X, y, weights, k, C, accuracy, step_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4492255170351749,\n",
       " 0.69020439780758,\n",
       " 0.427981931378195,\n",
       " 0.6983415847466344,\n",
       " 0.6144016895606225]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "sigm = [1 / (1 + exp(-w1 * x1 - w2 * x2)) for x1, x2 in zip(X['first_feature'], X['second_feature'])]\n",
    "sigm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49440251422180526,\n",
       " 0.5294965576808812,\n",
       " 0.49573696655047256,\n",
       " 0.5282281442636334,\n",
       " 0.5209669501758519]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# sigm_l2 = [1 / (1 + exp(-w1_l2 * x['first_feature'] - w2_l2 * x['second_feature'])) for _, x in X.iterrows()]\n",
    "sigm_l2 = [1 / (1 + exp(-w1_l2 * x1 - w2_l2 * x2)) for x1, x2 in zip(X['first_feature'], X['second_feature'])]\n",
    "sigm_l2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9268571428571428"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "a1 = roc_auc_score(y, sigm)\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9362857142857142"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = roc_auc_score(y, sigm_l2)\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1: 0.927 a2: 0.936\n"
     ]
    }
   ],
   "source": [
    "print(f\"a1: {round(a1, 3)} a2: {round(a2, 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
